import cv2 
import numpy as np
import matplotlib.pyplot as plt
import os
import lm
from scipy import ndimage
import pyximport
pyximport.install()
import description
import utilities
import logging
import glob
import random

# create list of filenames
files = glob.glob(r"D:\BEAM\Scripts\PackImagesToHDF5\pi-camera-data-127001-2019-10-14T12-41-20-unpack\png"+r"\*.png")
# specific range
frange = [91398,150000]
files = files[frange[0]:frange[1]]

# setup logger
log = logging.getLogger(__name__)
# set formatting style
logging.basicConfig(format="[{filename}:{lineno}:{levelname} - {funcName}() ] {message}",style='{')
log.setLevel(logging.INFO)

# parameters for SLICO algorithm
region_size = 4
ruler = 15.0
ratio = 0.075
min_element_size = 4
num_iterations = 10

# take a screenshot from the default camera, perform SLICO, calculate the features of each superpixels and train an EM algorithm using it
# the SLICO parameters are set at the top of the program
# function accepts the number of clusters it should be separated by
# returns the following
#   - frame : Image obtained
#   - labels : Labels matrix generated by superpixels
#   - probs : Posteriori probabilities of each Gaussian Mixture component
#   - em    : Trained EM class
def trainEMUsingScreenshotFeatures(trainFiles,nc=2,sv=1000):
    os.makedirs("thermalModel",exist_ok=True)
    ## check for existing models
    models = glob.glob("thermalModel/*.xml")
    if len(models) >0:
        # find the model with the largest number
        modelPath = max(models,key=lambda x : int(os.path.splitext(os.path.basename(x))[0].split("thermalModel_")[1]))
        # load model
        print(f"found model {modelPath}")
        print("loading model")
        try:
            em = cv2.ml.EM_load(modelPath)
        except cv2.error as err:
            print(err)
            print("Failed to read in model. Starting from fresh")
            em = cv2.ml.EM_create()
    else:
        # create EM algorithm class
        em = cv2.ml.EM_create()
    # set the number of classes/clusters
    logging.debug(f"Setting the number of clusters to {nc}")
    em.setClustersNumber(nc)
    # iterate over training files
    for fi,f in enumerate(trainFiles):
        print(f"{fi}/{len(trainFiles)} ({fi/len(trainFiles)})")
        if ((fi%sv)==0) and (fi>0):
            print("saving model")
            em.save(os.path.join("thermalModel",f"thermalModel_{fi}.xml"))
        # get image
        frame = cv2.imread(f)
        # slico
        superpix = cv2.ximgproc.createSuperpixelSLIC(frame,cv2.ximgproc.SLICO,region_size,ruler)
        superpix.iterate(num_iterations)
        if min_element_size>0:
            superpix.enforceLabelConnectivity(min_element_size)
        # get labels
        # auto generated number controlled by min_element_size
        labels = superpix.getLabels()
        # calculate color features
        log.debug("Calculating color features")
        colF = description.calculateAllColorFeatures(frame,labels)
        log.debug("normalizing the color features")
        colF = description.normalizeFeatures(colF)
        log.debug("Building texture filter bank")
        # build texture filter bank
        fbank = lm.makeLMfilters()
        log.debug("Calculating texture features")
        # calculate response to texture filters
        textF = description.calculateTextureFeatureVector(frame,labels,fbank)
        log.debug("normalizing the texture vectors")
        textF = description.normalizeFeatures(textF)
        # build array of labels as additional feature
        logging.debug("Building label vector")
        ul = np.unique(labels)
        logging.debug("Concatenating the feature sets together")
        # concatenate features together to form feature vector
        fvector = np.concatenate((ul.reshape(-1,1),colF,textF),axis=1)
        log.info("Training EM")
        logging.debug("Building EM class")
        # train using built feature vector and returns the following:
        #   - retval :  flag indicating if it was successful
        #   - logLikelihoods : likelihood logarithm value for each sample
        #   - tlabels : Class label of each sample
        #   - probs : Optional output matrix that contains posterior probabilities of each gaussian mixture
        logging.debug("Training EM algorithm")
        em.trainEM(fvector)
    return em

        
if __name__ == "__main__":
    # split images into training and validation set
    split = 0.5
    # split list
    trainFiles = files[:int(len(files)*split)]
    # suffle
    random.shuffle(trainFiles)
    # get validation images
    validFiles = files[int(len(files)*split):]
    # run training script
    em = trainEMUsingScreenshotFeatures(trainFiles,2)
