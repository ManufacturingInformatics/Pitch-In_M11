import cv2 
import numpy as np
import matplotlib.pyplot as plt
import os
import lm
from scipy import ndimage
import pyximport
pyximport.install()
import description
import utilities
import logging
import glob
import random
import h5py

# create list of filenames
files = glob.glob(r"D:\BEAM\Scripts\PackImagesToHDF5\pi-camera-data-127001-2019-10-14T12-41-20-unpack\png"+r"\*.png")
# specific range
frange = [91398,150000]
files = files[frange[0]:frange[1]]

# setup logger
log = logging.getLogger(__name__)
# set formatting style
logging.basicConfig(format="[{filename}:{lineno}:{levelname} - {funcName}() ] {message}",style='{')
log.setLevel(logging.INFO)

# parameters for SLICO algorithm
region_size = 4
ruler = 15.0
ratio = 0.075
min_element_size = 4
num_iterations = 10

def findLatestModel(modelsPath):
    ## check for existing models
    models = glob.glob("thermalModel/*.xml")
    if len(models) >0:
        # find the model with the largest number
        modelPath = max(models,key=lambda x : int(os.path.splitext(os.path.basename(x))[0].split("thermalModel_")[1]))
        # load model
        print(f"found model {modelPath}")
        print("loading model")
        try:
            em = cv2.ml.EM_load(modelPath)
            return em
        except cv2.error as err:
            print(err)

def findSpecificModel(modelsPath,target):
    ## check for existing models
    models = glob.glob("thermalModel/*.xml")
    if len(models) >0:
        # find the model that matches target
        modelPath = [x for x in models if int(os.path.splitext(os.path.basename(x))[0].split("thermalModel_")[1])==target]
        # load model
        print(f"found model {modelPath}")
        print("loading model")
        try:
            em = cv2.ml.EM_load(modelPath[0])
            return em
        except cv2.error as err:
            print(err)

# take a screenshot from the default camera, perform SLICO, calculate the features of each superpixels and train an EM algorithm using it
# the SLICO parameters are set at the top of the program
# function accepts the number of clusters it should be separated by
# returns the following
#   - frame : Image obtained
#   - labels : Labels matrix generated by superpixels
#   - probs : Posteriori probabilities of each Gaussian Mixture component
#   - em    : Trained EM class
def trainEMUsingScreenshotFeatures(trainFiles,nc=2,sv=1000):
    os.makedirs("thermalModel",exist_ok=True)
    startIdx=0
    ## check for existing models
    models = glob.glob("thermalModel/*.xml")
    if len(models) >0:
        # find the model with the largest number
        modelPath = max(models,key=lambda x : int(os.path.splitext(os.path.basename(x))[0].split("thermalModel_")[1]))
        # load model
        print(f"found model {modelPath}")
        print("loading model")
        try:
            em = cv2.ml.EM_load(modelPath)
            startIdx = int(os.path.splitext(os.path.basename(modelPath))[0].split("thermalModel_")[1])
        except cv2.error as err:
            print(err)
            print("Failed to read in model. Starting from fresh")
            em = cv2.ml.EM_create()
    else:
        # create EM algorithm class
        em = cv2.ml.EM_create()
    # set the number of classes/clusters
    logging.debug(f"Setting the number of clusters to {nc}")
    em.setClustersNumber(nc)
    # iterate over training files
    for fi,f in enumerate(trainFiles[startIdx:],start=startIdx):
        print(f"{fi}/{len(trainFiles)} ({fi/len(trainFiles)})")
        # get image
        frame = cv2.imread(f)
        # slico
        superpix = cv2.ximgproc.createSuperpixelSLIC(frame,cv2.ximgproc.SLICO,region_size,ruler)
        superpix.iterate(num_iterations)
        if min_element_size>0:
            superpix.enforceLabelConnectivity(min_element_size)
        # get labels
        # auto generated number controlled by min_element_size
        labels = superpix.getLabels()
        # calculate color features
        log.debug("Calculating color features")
        colF = description.calculateAllColorFeatures(frame,labels)
        log.debug("normalizing the color features")
        colF = description.normalizeFeatures(colF)
        log.debug("Building texture filter bank")
        # build texture filter bank
        fbank = lm.makeLMfilters()
        log.debug("Calculating texture features")
        # calculate response to texture filters
        textF = description.calculateTextureFeatureVector(frame,labels,fbank)
        log.debug("normalizing the texture vectors")
        textF = description.normalizeFeatures(textF)
        # build array of labels as additional feature
        logging.debug("Building label vector")
        ul = np.unique(labels)
        logging.debug("Concatenating the feature sets together")
        # concatenate features together to form feature vector
        fvector = np.concatenate((ul.reshape(-1,1),colF,textF),axis=1)
        log.info("Training EM")
        logging.debug("Building EM class")
        # train using built feature vector and returns the following:
        #   - retval :  flag indicating if it was successful
        #   - logLikelihoods : likelihood logarithm value for each sample
        #   - tlabels : Class label of each sample
        #   - probs : Optional output matrix that contains posterior probabilities of each gaussian mixture
        logging.debug("Training EM algorithm")
        em.trainEM(fvector)
        if ((fi%sv)==0) and (fi>0):
            print("saving model")
            em.save(os.path.join("thermalModel",f"thermalModel_{fi}.xml"))
    return em

def testUsingModel(em,testFiles,fout="thermalModelTest"):
    os.makedirs(fout,exist_ok=True)
    fbank = lm.makeLMfilters()
    for fi,f in enumerate(testFiles):
        print(f"{fi}/{len(testFiles)} ({fi/len(testFiles)})")
        # get image
        frame = cv2.imread(f)
        # slico
        superpix = cv2.ximgproc.createSuperpixelSLIC(frame,cv2.ximgproc.SLICO,region_size,ruler)
        superpix.iterate(num_iterations)
        if min_element_size>0:
            superpix.enforceLabelConnectivity(min_element_size)
        # get labels
        # auto generated number controlled by min_element_size
        labels = superpix.getLabels()
        print(f"labels shape {labels.shape},{np.unique(labels).shape}")
        # calculate color features
        log.debug("Calculating color features")
        colF = description.calculateAllColorFeatures(frame,labels)
        log.debug("normalizing the color features")
        colF = description.normalizeFeatures(colF)
        print(f"color features shape {colF.shape}")
        log.debug("Building texture filter bank")
        # build texture filter bank
        fbank = lm.makeLMfilters()
        log.debug("Calculating texture features")
        # calculate response to texture filters
        textF = description.calculateTextureFeatureVector(frame,labels,fbank)
        log.debug("normalizing the texture vectors")
        textF = description.normalizeFeatures(textF)
        # build array of labels as additional feature
        logging.debug("Building label vector")
        ul = np.unique(labels)
        logging.debug("Concatenating the feature sets together")
        # concatenate features together to form feature vector
        fvector = np.concatenate((ul.reshape(-1,1),colF,textF),axis=1)
        log.info("Predicting using EM")
        # predict using model
        ret,res=em.predict(fvector)
        # results matrix is the prob of each cluster belonging to a specific class
        # find column of max prob occurs for each row i.e. the classification label
        #resmax = res.argmax(1)
        logging.debug("Generating results image")
        ## construct results matrix based on results
        # create empty matrix to update
        cres = np.zeros(labels.shape,dtype='uint8')
        for li in range(res.shape[0]):
            #print(l
            # find where the labels occur
            xx,yy = np.where(labels==li)
            # update matrix with classification result
            cres[xx,yy]=np.argmax(res[li,:])
        # save results as an image
        cv2.imwrite(os.path.join(fout,f"thermalModelTest_{fi:06d}.png"),cres)

def evaluateSingle(em,fin):
    fbank = lm.makeLMfilters()
    # get image
    frame = cv2.imread(fin)
    # slico
    superpix = cv2.ximgproc.createSuperpixelSLIC(frame,cv2.ximgproc.SLICO,region_size,ruler)
    superpix.iterate(num_iterations)
    if min_element_size>0:
        superpix.enforceLabelConnectivity(min_element_size)
    # get labels
    # auto generated number controlled by min_element_size
    labels = superpix.getLabels()
    print(f"labels shape {labels.shape},{np.unique(labels).shape}")
    # calculate color features
    log.debug("Calculating color features")
    colF = description.calculateAllColorFeatures(frame,labels)
    log.debug("normalizing the color features")
    colF = description.normalizeFeatures(colF)
    print(f"color features shape {colF.shape}")
    log.debug("Building texture filter bank")
    # build texture filter bank
    fbank = lm.makeLMfilters()
    log.debug("Calculating texture features")
    # calculate response to texture filters
    textF = description.calculateTextureFeatureVector(frame,labels,fbank)
    log.debug("normalizing the texture vectors")
    textF = description.normalizeFeatures(textF)
    # build array of labels as additional feature
    logging.debug("Building label vector")
    ul = np.unique(labels)
    logging.debug("Concatenating the feature sets together")
    # concatenate features together to form feature vector
    fvector = np.concatenate((ul.reshape(-1,1),colF,textF),axis=1)
    log.info("Predicting using EM")
    # predict using model
    ret,res=em.predict(fvector)
    # results matrix is the prob of each cluster belonging to a specific class
    # find column of max prob occurs for each row i.e. the classification label
    resmax = res.argmax(1)
    logging.debug("Generating results image")
    ## construct results matrix based on results
    # create empty matrix to update
    cres = np.zeros(labels.shape,dtype='uint8')
    for li in range(res.shape[0]):
        #print(li)
        # find where the labels occur
        xx,yy = np.where(labels==li)
        # update matrix with classification result
        cres[xx,yy]=resmax[li]
    return cres,res

def testUsingModelHDF5(em,testFiles,fout="thermalModelTest.hdf5"):
    #os.makedirs(fout,exist_ok=True)
    fbank = lm.makeLMfilters()
    dset=None
    with h5py.File(fout,'w') as file:
        for fi,f in enumerate(testFiles):
            print(f"{fi}/{len(testFiles)} ({fi/len(testFiles)})")
            # get image
            frame = cv2.imread(f)
            # slico
            superpix = cv2.ximgproc.createSuperpixelSLIC(frame,cv2.ximgproc.SLICO,region_size,ruler)
            superpix.iterate(num_iterations)
            if min_element_size>0:
                superpix.enforceLabelConnectivity(min_element_size)
            # get labels
            # auto generated number controlled by min_element_size
            labels = superpix.getLabels()
            print(f"labels shape {labels.shape},{np.unique(labels).shape}")
            # calculate color features
            log.debug("Calculating color features")
            colF = description.calculateAllColorFeatures(frame,labels)
            log.debug("normalizing the color features")
            colF = description.normalizeFeatures(colF)
            print(f"color features shape {colF.shape}")
            log.debug("Building texture filter bank")
            # build texture filter bank
            fbank = lm.makeLMfilters()
            log.debug("Calculating texture features")
            # calculate response to texture filters
            textF = description.calculateTextureFeatureVector(frame,labels,fbank)
            log.debug("normalizing the texture vectors")
            textF = description.normalizeFeatures(textF)
            # build array of labels as additional feature
            logging.debug("Building label vector")
            ul = np.unique(labels)
            logging.debug("Concatenating the feature sets together")
            # concatenate features together to form feature vector
            fvector = np.concatenate((ul.reshape(-1,1),colF,textF),axis=1)
            log.info("Predicting using EM")
            # predict using model
            _,res=em.predict(fvector)
            if dset is None:
                dset = file.create_dataset("res",(48,2,1),maxshape=(48,2,None))
            # update last index
            # NUMBER OF CLUSTERS NOT CONSISTENT
            # ESTIMATED MAX is 48
            dset[:res.shape[0],:res.shape[1],-1]=res
            # increase size of dataset by one "frame"
            dset.resize((*dset.shape[:2],dset.shape[-1]+1))

def tryAllModels(models,testFiles):
    # ensure models are sorted
    models.sort(key=lambda x: int(os.path.splitext(os.path.basename(x))[0].split('_')[1]))
    # iterate over models
    for modelPath in models:
        # attempt to load model
        try:
            model = cv2.ml.EM_load(modelPath)
            # if loading successful
            # find classificatio
            testUsingModelHDF5(model,testFiles,fout=f"thermalModelTest_{int(os.path.splitext(os.path.basename(x))[0].split('_')[1])}.hdf5")
        except cv2.error as err:
            print(err)
            log.error(str(err))
            log.error(f"Unable to load model {modelPath}!")

def colorResults(fin,fout="labelsColor",cmap=cv2.COLORMAP_HOT):
    imgin= glob.glob(os.path.join(fin,"*"),recursive=True)
    os.makedirs(fout,exist_ok=True)
    for ff in imgin:
        # read in image
        img = cv2.imread(ff,cv2.IMREAD_GRAYSCALE)
        # convert to float
        img = img.astype("float64")
        # normalize to 0-255
        img *= 255.0/img.max()
        img = img.astype("uint8")
        img=cv2.applyColorMap(img,cmap)
        p = os.path.basename(ff)
        if not cv2.imwrite(os.path.join(fout,p),img):
            print(f"Failed to write output image to {p}")
            
if __name__ == "__main__":
    # split images into training and validation set
    split = 0.5
    # split list
    #trainFiles = files[:int(len(files)*split)]
    # suffle
    #random.shuffle(trainFiles)
    # get validation images
    #validFiles = files[int(len(files)*split):]
    # run training script
    #em = trainEMUsingScreenshotFeatures(trainFiles,2)

    ## test using training files
    # get latest model
    #em = findLatestModel("Models\CustomPipeline")
    em = em = findSpecificModel("",14000)
    # get training files to use for testing
    with open("thermalTrainList.txt",'r') as file:
        testFiles = [ff.strip() for ff in file]
    # define output path
    testUsingModel(em,testFiles,"thermalModelTrainTest_14k")
    colorResults("thermalModelTrainTest_14k","thermalModelTrainTest_14k_color")
    #testUsingModelHDF5(em,testFiles)
